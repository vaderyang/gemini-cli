# Example .env file for OpenAI integration

# For OpenAI API
OPENAI_API_KEY=your-openai-api-key-here

# For local OpenAI-compatible endpoints (e.g., LM Studio, Ollama)
OPENAI_BASE_URL=http://localhost:1234/v1

# Optional: Override the default model
# Default is gpt-4, but you can use any model supported by your endpoint
# GEMINI_MODEL=gpt-3.5-turbo
# GEMINI_MODEL=mistral-7b-instruct
# GEMINI_MODEL=llama-2-70b-chat